{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fd8c5d-c2f0-4167-9e8f-24b329fd33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47655f91-f6d7-4d6a-a202-fcd7cb44ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query):\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Extract the first result (assuming it's the Queensland Health website)\n",
    "    first_result = soup.find('div', class_='yuRUbf')\n",
    "    if first_result:\n",
    "        link = first_result.find('a')['href']\n",
    "        return link\n",
    "    return \"https://www.health.qld.gov.au/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e808f76a-e6a4-4df2-bbfb-ef4b9618042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_clinics(url):\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    clinics = []\n",
    "    # Adjust the following line based on the actual HTML structure of the website\n",
    "    for clinic in soup.find_all('div', class_='clinic-info'):\n",
    "        name = clinic.find('h2').text.strip()\n",
    "        link = clinic.find('a')['href']\n",
    "        clinics.append({'name': name, 'link': link})\n",
    "    return clinics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184814cd-8310-4d5a-931a-bcaccf189b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_clinic_details(url):\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract phone number\n",
    "    phone = soup.find('a', href=lambda href: href and href.startswith('tel:'))\n",
    "    phone = phone.text if phone else None\n",
    "    \n",
    "    # Extract address\n",
    "    address = None\n",
    "    address_pattern = r'(?:[\\w\\s]+,\\s*)*QLD\\s+\\d{4}'\n",
    "    address_match = re.search(address_pattern, soup.text)\n",
    "    if address_match:\n",
    "        address = address_match.group()\n",
    "    \n",
    "    return {'phone': phone, 'address': address}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01ce166-4414-4f4a-a22e-ff08898cc8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping from URL: https://www.health.qld.gov.au/\n",
      "No data was collected.\n"
     ]
    }
   ],
   "source": [
    "qld_health_url = google_search(\"Queensland Health\")\n",
    "\n",
    "# Ensure the URL has a scheme\n",
    "if not qld_health_url.startswith(('http://', 'https://')):\n",
    "    qld_health_url = 'https://' + qld_health_url\n",
    "\n",
    "print(f\"Scraping from URL: {qld_health_url}\")\n",
    "\n",
    "try:\n",
    "    clinics = scrape_clinics(qld_health_url)\n",
    "except Exception as e:\n",
    "    print(f\"Error scraping clinics: {str(e)}\")\n",
    "    clinics = []\n",
    "\n",
    "data = []\n",
    "for clinic in clinics:\n",
    "    time.sleep(random.uniform(1, 3))  # Random delay between requests\n",
    "    try:\n",
    "        details = scrape_clinic_details(clinic['link'])\n",
    "        clinic_data = {**clinic, **details}\n",
    "        \n",
    "        # Check for missing information and try to fill it\n",
    "        if not clinic_data['phone']:\n",
    "            clinic_data['phone'] = google_search_missing_info(clinic['name'], 'Phone')\n",
    "        if not clinic_data['address']:\n",
    "            clinic_data['address'] = google_search_missing_info(clinic['name'], 'Address')\n",
    "        \n",
    "        data.append(clinic_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing clinic {clinic['name']}: {str(e)}\")\n",
    "\n",
    "# Only create DataFrame if data was collected\n",
    "if data:\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('queensland_health_clinics.csv', index=False)\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No data was collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749fc3d6-3059-4f71-8f0a-44c40ae9833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayed_search(clinic_name, info_type):\n",
    "    time.sleep(random.uniform(2, 5))  # Random delay between 2 and 5 seconds\n",
    "    return google_search_missing_info(clinic_name, info_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5da6f9-bf83-4602-ad60-8d2254976073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
